#!/usr/bin/env node

/**
 * Script para configurar o Ollama e baixar o modelo Gemma 2B
 * Execute: node scripts/setup-ollama.js
 */

const OLLAMA_BASE_URL = process.env.OLLAMA_BASE_URL || 'http://localhost:11434';
const MODEL_NAME = process.env.OLLAMA_MODEL || 'gemma2b';

async function checkOllamaStatus() {
  try {
    console.log('üîç Verificando status do Ollama...');
    const response = await fetch(`${OLLAMA_BASE_URL}/api/tags`);
    
    if (response.ok) {
      const data = await response.json();
      console.log('‚úÖ Ollama est√° rodando!');
      console.log('üìã Modelos dispon√≠veis:', data.models?.map(m => m.name).join(', ') || 'Nenhum');
      return true;
    } else {
      console.log('‚ùå Ollama n√£o est√° respondendo');
      return false;
    }
  } catch (error) {
    console.log('‚ùå Erro ao conectar com Ollama:', error.message);
    return false;
  }
}

async function checkModelAvailability() {
  try {
    console.log(`üîç Verificando se o modelo ${MODEL_NAME} est√° dispon√≠vel...`);
    const response = await fetch(`${OLLAMA_BASE_URL}/api/tags`);
    
    if (response.ok) {
      const data = await response.json();
      const modelExists = data.models?.some(m => m.name === MODEL_NAME);
      
      if (modelExists) {
        console.log(`‚úÖ Modelo ${MODEL_NAME} j√° est√° dispon√≠vel!`);
        return true;
      } else {
        console.log(`‚ùå Modelo ${MODEL_NAME} n√£o encontrado`);
        return false;
      }
    }
    return false;
  } catch (error) {
    console.log('‚ùå Erro ao verificar modelo:', error.message);
    return false;
  }
}

async function downloadModel() {
  try {
    console.log(`üì• Baixando modelo ${MODEL_NAME}...`);
    console.log('‚ö†Ô∏è  Isso pode demorar alguns minutos dependendo da sua conex√£o...');
    
    const response = await fetch(`${OLLAMA_BASE_URL}/api/pull`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        name: MODEL_NAME,
      }),
    });

    if (!response.ok) {
      throw new Error(`Erro ao baixar modelo: ${response.status}`);
    }

    console.log(`‚úÖ Modelo ${MODEL_NAME} baixado com sucesso!`);
    return true;
  } catch (error) {
    console.error('‚ùå Erro ao baixar modelo:', error.message);
    return false;
  }
}

async function testModel() {
  try {
    console.log('üß™ Testando o modelo...');
    
    const testPrompt = 'Ol√°! Como voc√™ est√°?';
    const response = await fetch(`${OLLAMA_BASE_URL}/api/generate`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: MODEL_NAME,
        prompt: testPrompt,
        stream: false,
        options: {
          temperature: 0.7,
          top_p: 0.9,
          max_tokens: 100,
        }
      }),
    });

    if (!response.ok) {
      throw new Error(`Erro no teste: ${response.status}`);
    }

    const data = await response.json();
    console.log('‚úÖ Teste bem-sucedido!');
    console.log('üìù Resposta de teste:', data.response?.substring(0, 100) + '...');
    return true;
  } catch (error) {
    console.error('‚ùå Erro no teste:', error.message);
    return false;
  }
}

async function main() {
  console.log('üöÄ Configurando Ollama para Gemma 2B...\n');
  
  // Verificar se o Ollama est√° rodando
  const ollamaRunning = await checkOllamaStatus();
  if (!ollamaRunning) {
    console.log('\n‚ùå Ollama n√£o est√° rodando!');
    console.log('üìã Para resolver:');
    console.log('   1. Instale o Ollama: https://ollama.ai/');
    console.log('   2. Execute: ollama serve');
    console.log('   3. Ou use Docker: docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama');
    console.log('   4. Execute este script novamente');
    process.exit(1);
  }

  // Verificar se o modelo j√° est√° dispon√≠vel
  const modelAvailable = await checkModelAvailability();
  
  if (!modelAvailable) {
    console.log(`\nüì• Modelo ${MODEL_NAME} n√£o encontrado. Baixando...`);
    const downloadSuccess = await downloadModel();
    
    if (!downloadSuccess) {
      console.log('\n‚ùå Falha ao baixar o modelo');
      process.exit(1);
    }
  }

  // Testar o modelo
  console.log('\nüß™ Testando o modelo...');
  const testSuccess = await testModel();
  
  if (testSuccess) {
    console.log('\nüéâ Configura√ß√£o conclu√≠da com sucesso!');
    console.log(`‚úÖ Ollama est√° rodando em: ${OLLAMA_BASE_URL}`);
    console.log(`‚úÖ Modelo ${MODEL_NAME} est√° dispon√≠vel e funcionando`);
    console.log('\nüìã Para usar em produ√ß√£o:');
    console.log('   - Configure as vari√°veis de ambiente:');
    console.log(`     OLLAMA_BASE_URL=${OLLAMA_BASE_URL}`);
    console.log(`     OLLAMA_MODEL=${MODEL_NAME}`);
    console.log('   - Reinicie sua aplica√ß√£o');
  } else {
    console.log('\n‚ùå Falha no teste do modelo');
    process.exit(1);
  }
}

// Executar se chamado diretamente
if (require.main === module) {
  main().catch(console.error);
}

module.exports = {
  checkOllamaStatus,
  checkModelAvailability,
  downloadModel,
  testModel
};
